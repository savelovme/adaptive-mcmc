Here we make the following (restrictive) assumption:
\begin{assumption}[Bounded eccentricity]
\label{a:eccentricity}
There exist some $K > 0$, s.t. for any $x \in \mathcal{X}$ holds
\[
E(x) \leq K.
\]
\end{assumption}

We also assume that \ref{a:markov}, \ref{a:contraction} hold, and $u_\gamma$ is given by \eqref{eq:poisson-neumann}

Lemma from Appendix A of \cite{laitinen2024invitationadaptivemarkovchain}:
\begin{lemma}
\label{lem:h-measurable}
Let $h:\mathcal{I} \times \mathcal{X} \to \mathbb{R}$ be $\mathcal{F}_{\mathcal{I}}\otimes\mathcal{F}_{\mathcal{X}}$-measurable and bounded. Then, under \ref{a:regularity} and \ref{a:markov}
\[
  \mexp{h(\Gamma_k, X_{k+1})\mid \mathcal{F}_k} \aseq \int_{\mathcal{X}} h(\Gamma_k, y) P_{\Gamma_k}(X_k, dy) .
\]
\end{lemma}

The following lemma establishes that $(\Delta_k)_{k \in \mathbb{N}}$ are bounded martingale differences with respect to $(\mathcal{F}_k)_{k \in \mathbb{N}}$, and therefore $M_n = \sum_{k=1}^n \Delta_k$ is a martingale. 

\begin{lemma}
\label{lemma:martingale}
Let $u_\gamma$ be defined as in \eqref{eq:poisson-neumann}
then for all $k \in \mathbb{N}$, the terms
\[
   \Delta_k = u_{\Gamma_{k-1}}(X_k) - P_{\Gamma_{k-1}}u_{\Gamma_{k-1}}(X_{k-1})
\]
are bounded, $\mathcal{F}_k$-measurable and satisfy:
\begin{align*}
      \mexp{ \Delta_k \mid \mathcal{F}_{k-1} } & \aseq  0 \\
      \mexp{ \Delta_k^2 \mid \mathcal{F}_{k-1}} & \aseq 
      P_{\Gamma_{k-1}} u_{\Gamma_{k-1}}^2 (X_{k-1}) - (P_{\Gamma_{k-1}} u_{\Gamma_{k-1}})^2(X_{k-1}).
\end{align*}
\end{lemma}
\begin{proof} 
Boundedness and measurability follow from 
Proposition \ref{prop:poisson_equation_wasserstein_setting}:

\[
|\Delta_k|\le \| u_{\Gamma_k} \|_\infty + \| P_{\Gamma_{k-1}}u_{\Gamma_{k-1}} \|_\infty 
   \le \| u_{\Gamma_k} \|_\infty + \| u_{\Gamma_{k-1}} \|_\infty < \infty,
\]

Further, Lemma \ref{lem:h-measurable} yields:
\begin{align*}
    \mexp{\Delta_k \mid \mathcal{F}_{k-1}} 
    &= \mexp{ u_{\Gamma_{k-1}}(X_k) \mid \mathcal{F}_{k-1}} - P_{\Gamma_{k-1}}u_{\Gamma_{k-1}}(X_{k-1}) \\
    & \aseq P_{\Gamma_{k-1}}u_{\Gamma_{k-1}}(X_{k-1}) - P_{\Gamma_{k-1}}u_{\Gamma_{k-1}}(X_{k-1}) \\ 
    &= 0
\end{align*}

Similarly, 
\begin{align*}
&\mexp{\Delta_k^2 \mid \mathcal{F}_{k-1}} \\
&\aseq \mexp{u_{\Gamma_{k-1}}^2(X_k) - 2u_{\Gamma_{k-1}}(X_k)P_{\Gamma_{k-1}}u_{\Gamma_{k-1}}(X_{k-1})+(P_{\Gamma_{k-1}}u_{\Gamma_{k-1}})^2(X_{k-1}) \mid \mathcal{F}_{k-1}} \\ 
&\aseq \mexp{u_{\Gamma_{k-1}}^2(X_k) \mid \mathcal{F}_{k-1}}- 2P_{\Gamma_{k-1}}u_{\Gamma_{k-1}}(X_{k-1})\mexp{u_{\Gamma_{k-1}}(X_k) \mid \mathcal{F}_{k-1}}+(P_{\Gamma_{k-1}}u_{\Gamma_{k-1}})^2(X_{k-1}) \\ 
&\aseq P_{\Gamma_{k-1}}u_{\Gamma_{k-1}}^2(X_k)- 2(P_{\Gamma_{k-1}}u_{\Gamma_{k-1}})^2(X_{k-1})+(P_{\Gamma_{k-1}}u_{\Gamma_{k-1}})^2(X_{k-1}) \\ 
&\aseq P_{\Gamma_{k-1}}u_{\Gamma_{k-1}}^2(X_k)-(P_{\Gamma_{k-1}}u_{\Gamma_{k-1}})^2(X_{k-1}). \qedhere
\end{align*}
\end{proof}

The following lemma ensures that the terms $R_n/n$ and $M_n/n$ vanish, as required by a law of large numbers. The term $R_n/\sqrt{n}$ vanishes, too, and $M_n/\sqrt{n}$ will converge to a Gaussian limit as shown in Lemma \ref{lem:martingale-term-clt}.

\begin{lemma}
   \label{lem:control-RM}
Let $u_\gamma$ be defined as in \eqref{eq:poisson-neumann}, then the following hold as $n\to\infty$:
\[
\frac{R_n}{n} \to 0, \qquad \frac{R_n}{\sqrt{n}}\to 0 \qquad \text{and}\qquad \frac{M_n}{n} \to 0,\qquad\text{(a.s.)}
\]
\end{lemma}
\begin{proof}
Since $R_n$ is a telescopic, we have for $p\in\{1,1/2\}$:
\[
\bigg|\frac{R_n}{n^p}\bigg|
=\frac{1}{n^p}\big|P_{\Gamma_{n}}u_{\Gamma_{n}}(X_{n})- P_{\Gamma_0}u_{\Gamma_0}(X_0)\big|
\le \frac{1}{n^p} \big( \| P_{\Gamma_{n}}u_{\Gamma_{n}} \|_\infty + \| P_{\Gamma_0}u_{\Gamma_0} \|_\infty \big) \to 0,
\]
because the functions are uniformly bounded.

For the remaining term, consider the following martingale:
\begin{align*}
   V_n=\sum_{k=1}^n\frac{\Delta_k}{k},
\end{align*}
where the martingale differences $\|\Delta_k\|_\infty < M$ for some constant $M<\infty$.
Deduce it from \ref{prop:poisson_equation_wasserstein_setting}.

Because martingale differences are orthogonal, we have
\[
   \mexp{V_n^2}=\sum_{k=1}^n\frac{\mexp{\Delta_k^2}}{k^2} \le M^2 \sum_{k=1}^\infty \frac{1}{k^2} = M^2 \frac{\pi^2}{6}.
\]
That is, $V_n$ is a $L^2$-bounded martingale, which converges to an a.s.~finite $V_\infty = \sum_{k=1}^\infty\frac{\Delta_k}{k}$ almost surely (see Corollary E.3.5 in \cite{douc2018markov}). Whenever $V_\infty$ is finite, Kronecker's lemma implies that 
\begin{equation*}
\frac{M_n}{n}=\frac{1}{n}\sum_{k=1}^n k \frac{\Delta_k}{k}\xrightarrow{n\to\infty} 0.
\qedhere
\end{equation*}
\end{proof}

We record the following abstract assumption and a lemma which ensures a central limit theorem for the martingale term.

\begin{assumption}
   \label{a:limiting-poisson}
Suppose that there exists a constant $\sigma_\varphi^2\in[0,\infty)$ such that
\[
   \frac{1}{n} \sum_{k=1}^n 
   {P_{\Gamma_{k-1}} u_{\Gamma_{k-1}}^2 (X_{k-1}) - (P_{\Gamma_{k-1}} u_{\Gamma_{k-1}})^2(X_{k-1})} 
   \xrightarrow{n\to\infty} \sigma_\varphi^2 \qquad \text{in probability.}
\]
\end{assumption}

\begin{lemma}
   \label{lem:martingale-term-clt}
Assume that \ref{a:limiting-poisson} holds, then
\[
   \frac{M_n}{\sqrt{n}} \xrightarrow{n\to\infty} N(0,\sigma_\varphi^2) \qquad \text{in distribution.}
\]
\end{lemma}
\begin{proof}
   The result follows from a martingale central limit theorem (See Corollary E.4.2 in \cite{douc2018markov}). 
   
   By Lemma \ref{lemma:martingale}:
   $$
   \frac{1}{n} \sum_{k=1}^n \mexp{\Delta_k^2 \mid \mathcal{F}_{k-1}}
   = \frac{1}{n} \sum_{k=1}^n 
   {P_{\Gamma_{k-1}} u_{\Gamma_{k-1}}^2 (X_{k-1}) - (P_{\Gamma_{k-1}} u_{\Gamma_{k-1}})^2(X_{k-1})} 
   \to \sigma_{\varphi}^2,
   $$
   due to \ref{a:limiting-poisson}. Since $\{ \Delta_k \}_{k \in \mathbb{N}}$ are uniformly bounded, $\Delta_k^2 \mathbb{I}_{\{|\Delta_k| \ge \epsilon \sqrt{n}\}}$ are identically zero for sufficiently large $n$.
\end{proof}

We present later verifiable conditions which imply \ref{a:limiting-poisson} (Lemma \ref{lem:convergence-continuity-clt} in Section \ref{sec:sa}).


% \section{Waning adaptation}
% \label{sec:waning}

% Lemma \ref{lem:control-RM} in Section \ref{sec:uniform} showed that under \ref{a:markov} and \ref{a:simultaneous-uniform}, the terms $R_n/n$, $R_n/\sqrt{n}$ and $M_n/n$ in the decomposition \eqref{eq:main-decomposition} vanish as $n\to\infty$, and $M_n/\sqrt{n}$ converges to a Gaussian limit under \ref{a:limiting-poisson} (Lemma \ref{lem:martingale-term-clt}). 

% In order to establish a law of large numbers and a central limit theorem, we only need to establish that $A_n/n\to 0$ and $A_n/\sqrt{n}\to 0$, respectively. The following general assumption will guarantee this:

% \begin{assumption}[Waning adaptation]
%    \label{a:waning}
%    Let $D_k$ be random numbers taking values in $[0,1]$ such that 
%    $$
%    \sup_{x\in\mathcal{X}} d_\tv \big( P_{\Gamma_k}(x,\uarg), P_{\Gamma_{k-1}}(x,\uarg)\big) \le D_k.
%    $$
%    If the following holds for $p>0$:
%    $$
%       \frac{1}{n^p} \sum_{k=1}^n D_k \to 0 \qquad \text{(in probability/almost surely)},
%    $$
%    then the adaptation is said to be \emph{$p$-waning} (weakly/strongly, respectively).
% \end{assumption}

% \begin{theorem}
%    \label{thm:waning-convergence}
% Suppose that adaptation is weakly/strongly $p$-waning. Then,
% $$
%    \frac{A_n}{n^p} \xrightarrow{n\to\infty} 0,
% $$
% in probability/almost surely, respectively.
% \end{theorem}

% The proof of Theorem \ref{thm:waning-convergence} is preceded by the following key technical result, which establishes an upper bound for the individual terms in the sum $A_n$.

% \begin{lemma}\label{lemma:ineq-D}
%    % Under \ref{a:simultaneous-uniform} and with $\varphi\in L^\infty$, the functions $u_\gamma$ defined in Theorem \ref{thm:bounded} satisfy 
%    % $$
%    %    \| g_{s} - g_{s'} \|_\infty \le \frac{4 C^2}{(1-\rho)^2} \osc(\varphi) \sup_{x\in\mathcal{X}} d_\tv\big( P_s(x,\uarg), P_{s'}(x,\uarg) \big)
%    %    \qquad\text{for all }s,s'\in\mathcal{I}.
%    % $$
% \end{lemma}
% \begin{proof}
% Let $s,s'\in\mathcal{I}$ and $n\ge 1$, and write the telescopic sum
% \begin{align*}
% P_s^n\bar{\varphi}(x)-P_{s'}^n\bar{\varphi}(x)
% &=\sum_{i=0}^{n-1} \big(P_s^{i+1}P_{s'}^{n-(i+1)}\bar{\varphi}(x)-P_s^{i}P_{s'}^{n-i}\bar{\varphi}(x)\big)  \\
% &=\sum_{i=0}^{n-1} P_s^{i}(P_s-P_{s'})P_{s'}^{n-i-1}\bar{\varphi}(x).
% \end{align*}
% For an operator $G \colon (L_0^\infty(\pi),\|\cdot \|_\infty)\to (L_0^\infty(\pi),\|\cdot \|_\infty)$, we use the operator norm:
% $$\|G\|_{L_0^{\infty}(\pi)}=\sup_{h\in L_{0}^\infty(\pi),\, \|h\|_\infty \le 1}\|Gh\|_\infty.$$
% We have by Lemma \ref{lemma:bounded}, that $(P_s-P_{s'})$ and $P_s^k$ for all $k\in \mathbb{N}$ are bounded operators. 
% Therefore, by the sub-multiplicativity of the operator norm
% \begin{align*}
% \|P_s^n\bar{\varphi}-P_{s'}^n\bar{\varphi}\|_\infty 
% &\le \sum_{i=0}^{n-1} \|P_s^{i}\|_{L_0^\infty(\pi)} \|P_s-P_{s'}\|_{L_0^\infty(\pi)}  \|P_{s'}^{n-i-1}\bar{\varphi}\|_\infty.
% \end{align*}
% The last term can be controlled by Lemma \ref{lemma:bounded}, which yields
% \begin{align*}
% \|P_{s'}^{n-i-1}\bar{\varphi}\|_\infty \le C \rho^{n-i-1} \osc(\varphi),
% \end{align*}
% and, similarly, the first term is upper bounded by
% \begin{align*}
% \|P_s^{i}\|_{L_0^\infty(\pi)}&=\sup_{h\in L_0^\infty(\pi),\,  \|h\|_\infty \le 1}\|P_s^{i}h\|_\infty 
% \le 2 C \rho^i.
% \end{align*}
% For the remaining term, we may write 
% \begin{align*}
% \|P_s-P_{s'}\|_{L_0^\infty(\pi)}&=\sup_{h\in L_0^\infty(\pi),\,\|h\|_\infty \le 1}\|(P_s-P_{s'})h\|_\infty \\
% &\le \sup_{\|h\|_\infty \le 1}\|(P_s-P_{s'})h\|_\infty \\
% &=\sup_{x\in \mathcal{X}}  \sup_{\|h\|_\infty \le 1}|P_sh(x)-P_{s'}h(x)| \\
% &\le 2\sup_{x\in \mathcal{X}} d_\tv\big(P_s(x,\uarg),P_{s'}(x,\uarg)\big).
% \end{align*}
% Let $D = \sup_{x\in\mathcal{X}} d_\tv\big(P_s(x,\uarg),P_{s'}(x,\uarg)\big)$, then combining these bounds yields
% \begin{align*}
% \|P_{s}^n\bar{\varphi}-P_{s'}^n\bar{\varphi}\|_\infty
% & \le \sum_{i=0}^{n-1} 4C^2\rho^{n-1} \osc(\varphi) D
%  = 4C^2n\rho^{n-1} \osc(\varphi) D,
% \end{align*}
% and consequently,
% \begin{align}
% \|g_{s}-g_{s'}\|_\infty
% &\le \sum_{n=0}^\infty \|P_{s}^{n+1}\bar{\varphi}-P_{s'}^{n+1}\bar{\varphi}\|_\infty \label{eq:poisson-trinagle} \\
% &\le 4 C^2 \osc(\varphi) D \sum_{n=0}^\infty (n+1) \rho^{n}  \nonumber\\
% &=\frac{4C^2}{(1-\rho)^2}\osc(\varphi) D. \nonumber \qedhere
% \end{align}
% \end{proof}

% \begin{proof}[Proof of Theorem \ref{thm:waning-convergence}]
% Thanks to Lemma \ref{lemma:ineq-D}, we have the upper bound:
% \begin{equation*}
%    \bigg| \frac{A_n}{n^p} \bigg|
%    \le \frac{1}{n^p} \sum_{k=1}^n \| u_{\Gamma_k} - u_{\Gamma_{k-1}} \|_\infty
%    \le  \frac{4C^2}{(1-\rho)^2}\osc(\varphi) \bigg( \frac{1}{n^p}\sum_{k=1}^n  D_k \bigg). \qedhere
% \end{equation*}
% \end{proof}

% We are ready to state our main abstract convergence theorem.

% \begin{theorem}
% Suppose that \ref{a:markov} and \ref{a:simultaneous-uniform} hold and $\varphi\in L^\infty$, and adaptation is $p$-waning strongly/weakly \ref{a:waning}.
% \begin{enumerate}[(i)]
%    \item \label{item:wlln} If $p=1$, then the weak law of large numbers holds, that is, \eqref{eq:lln} in probability.
%    \item \label{item:slln} If $p=1$ strongly, then then the strong law of large numbers holds, that is, \eqref{eq:lln} a.s.
%    \item \label{item:clt} If $p=1/2$ and and \ref{a:limiting-poisson} holds with $\sigma_\varphi^2$, then the central limit theorem \eqref{eq:clt} holds with $\sigma_\varphi^2$.
% \end{enumerate}
% \end{theorem}
% \begin{proof}
%    For \eqref{item:wlln} and \eqref{item:slln}, consider the decomposition \ref{eq:main-decomposition}, where the terms $M_n/n\to 0$ and $R_n/n\to 0$ a.s.~by Lemma \ref{lem:control-RM}, and $A_n/n\to 0$ in probability/a.s.~due to Theorem \ref{thm:waning-convergence}.

%    For the central limit theorem \eqref{item:clt}, we note similarly that $R_n/\sqrt{n}\to 0$ a.s.~by Lemma \ref{lem:control-RM}, $A_n/\sqrt{n}\to 0$ in probability by Theorem \ref{thm:waning-convergence}, and $M_n/\sqrt{n}\to N(0,\sigma_\varphi^2)$ in distribution. The result follows by Slutsky's lemma.
% \end{proof}

% We then turn into some sufficient conditions which ensure $p$-waning adaptation. The first such condition, \emph{diminishing adaptation} was originally introduced in the coupling context \citep{roberts-rosenthal}. It implies weak 1-waning.

% \begin{assumption}[Diminishing adaptation]
%    \label{a:diminishing}
%    For $D_k$ as in Assumption \ref{a:waning}, 
%    $$
%       D_k \to 0, \qquad \text{in probability.}
%    $$
% \end{assumption}

% \begin{lemma}
%    \label{lem:diminishing-implies-waning}
%    If \ref{a:diminishing} holds, then adaptation is weakly 1-waning \ref{a:waning}.
% \end{lemma}
% \begin{proof}
%    Because $D_k\in[0,1]$, \ref{a:diminishing} is clearly equivalent to $\mexp[D_k] \to 0$. Therefore,
%    $$\lim_{n\to\infty} \frac{1}{n} \sum_{k=1}^n \mexp[D_k] \to 0;
%    $$ 
%    see Lemma \ref{lem:convergent-serie-for-convergent-sequence} in Appendix \ref{app:calculus}.
% \end{proof}

% As a consequence, Theorem \ref{thm:waning-convergence} ensures that diminishing adaptation implies the weak law of large numbers (for bounded $\varphi$ when \ref{a:markov} and \ref{a:simultaneous-uniform} hold), which is similar to the original result of \cite{roberts-rosenthal}. If, however, $D_k\to 0$ at a certain rate, strong $p$-waning holds, and therefore strong law of large numbers and/or a central limit theorem can hold.

% \begin{assumption}[with rate $p>0$]
%    \label{a:diminishing-with-rate}
%    For $D_k$ as in Assumption \ref{a:waning}, the following holds:
%    $$
%       \sum_{k=1}^\infty \frac{\mexp[D_k]}{k^p} <\infty.
%    $$
% \end{assumption}
% \begin{lemma}
%    \label{lem:diminishing-rate-implies-strong-waning}
%    If \ref{a:diminishing-with-rate} holds for some $p>0$, then the adaptation is strongly $p$-waning \ref{a:waning}.
% \end{lemma}
% \begin{proof}
%    Let $Z_n = \sum_{k=1}^n D_k/k^p$ and $Z_\infty = \lim_{n\to\infty} Z_n$, where the limit exists in $[0,\infty]$ because $D_k\ge 0$. By monotone convergence, $\mexp[Z_\infty] = \lim_{n\to\infty} \mexp[Z_n] < \infty$, so $Z_\infty<\infty$ a.s. We may apply Kronecker's lemma yielding $n^{-p} \sum_{k=1}^n D_k \to 0$ a.s.
% \end{proof}